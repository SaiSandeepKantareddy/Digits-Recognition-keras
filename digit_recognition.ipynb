{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "You can use ** Keras ** to implement your model. Read more at [keras.io](https://keras.io/).\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0)). You are not expected to model your architecture precisely using this model nor get the same performance levels, but this is more to show an exampe of an approach used to solve this particular problem. We encourage you to try out different architectures for yourself and see what works best for you. Here is a useful [forum post](https://discussions.udacity.com/t/goodfellow-et-al-2013-architecture/202363) discussing the architecture as described in the paper and here is [another one](https://discussions.udacity.com/t/what-loss-function-to-use-for-multi-digit-svhn-training/176897) discussing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Load dependencies\n",
    "import os\n",
    "import copy\n",
    "import h5py\n",
    "import cPickle as pickle\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Convolution2D, Dense, Dropout, MaxPooling2D, Flatten\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D, concatenate, UpSampling2D, Conv2DTranspose\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 14s 1us/step\n",
      "11501568/11490434 [==============================] - 14s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic data based on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_numbers(numbers, number_labels, maxlength=5, digit_sz=(28, 28), return_label=False):\n",
    "    # Attention: Only coded to work with grayscale images at the moment.\n",
    "\n",
    "    # Randomly choose a number length:\n",
    "    img_len = np.random.choice(range(maxlength)) + 1\n",
    "    label = np.empty(5, dtype='str')\n",
    "\n",
    "    #print \"length: \", img_len\n",
    "\n",
    "\n",
    "    # Randomly choose where in our image the sequence of numbers will appear\n",
    "    if img_len < maxlength:\n",
    "        st_point = np.random.choice(maxlength - img_len)\n",
    "    else:\n",
    "        st_point = 0\n",
    "    \n",
    "    #print \"start:\", st_point\n",
    "\n",
    "    charmap = np.zeros(maxlength)\n",
    "    charmap[st_point:st_point + img_len] = 1\n",
    "    \n",
    "    #print \"charmap: \", charmap\n",
    "\n",
    "    # Define a blank character - this will ensure our input image always have the same dimensions\n",
    "    blank_char = np.zeros_like(digit_sz)\n",
    "    blank_lbl = \".\"\n",
    "\n",
    "    # Initialize a blank image with maxlen * digit_dz width and digit_sz height\n",
    "    new_img_len = maxlength * digit_sz[1]\n",
    "    new_img = np.zeros((digit_sz[0], new_img_len))\n",
    "    \n",
    "    # Fill in the image with random numbers from dataset, starting at st_point\n",
    "    for i, b in enumerate(charmap):\n",
    "        if b > 0:\n",
    "            n = np.random.choice(len(numbers))\n",
    "            st_pos = i * digit_sz[1]\n",
    "            new_img[:, st_pos:st_pos + digit_sz[1]] = numbers[n]\n",
    "            label[i] = str(number_labels[n])\n",
    "        else:\n",
    "            label[i] = blank_lbl\n",
    "\n",
    "    if return_label:\n",
    "        return new_img, label\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6' '4' '5' '9' '8']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmLAK3RhjYuL/ARVoMs+6JijlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e787b8850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create sample to test that function is working\n",
    "img, label = create_numbers(x_train, y_train, return_label=True)\n",
    "plt.imshow(img, cmap='gray')\n",
    "print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Python Generator to create an unlimited amount of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(numbers, number_labels, batch_size=32):\n",
    "    \"\"\"\n",
    "    This generator receives mnist digits and labels and returns a batch for training\n",
    "\n",
    "    Input:\n",
    "    numbers - array with mnist images.\n",
    "    number_labels - array with mnist labels.\n",
    "\n",
    "    Arguments:\n",
    "    batch_size - size of the mini batch\n",
    "\n",
    "    Output:\n",
    "    X_train and y_train\n",
    "    \"\"\"\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for batch_sample in range(batch_size):\n",
    "            img, label = create_numbers(numbers, number_labels, return_label=True)\n",
    "            \n",
    "            # Here we will convert the label to a format that Keras API can process:\n",
    "            n_label = np.zeros((5, 11), dtype='int')\n",
    "            for i, digit in enumerate(label):\n",
    "                if digit == \".\":\n",
    "                    n_digit = 10\n",
    "                else:\n",
    "                    n_digit = int(digit)\n",
    "\n",
    "                n_label[i][n_digit] = 1\n",
    "                \n",
    "\n",
    "            images.append(img)\n",
    "            #labels.append(label)\n",
    "            labels.append(n_label)\n",
    "\n",
    "        X_train = np.array(images)\n",
    "        if len(X_train.shape) == 3:\n",
    "            X_train = np.expand_dims(X_train, -1)\n",
    "\n",
    "        y_temp = np.array(labels)\n",
    "        \n",
    "        y1 = y_temp[:, 0, :]\n",
    "        y2 = y_temp[:, 1, :]\n",
    "        y3 = y_temp[:, 2, :]\n",
    "        y4 = y_temp[:, 3, :]\n",
    "        y5 = y_temp[:, 4, :]\n",
    "\n",
    "        yield X_train, [y1, y2, y3, y4, y5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    n_label = \"\"\n",
    "    for digit in label:\n",
    "        if np.argmax(digit) == 10:\n",
    "            n_digit = \".\"\n",
    "        else:\n",
    "            n_digit = str(np.argmax(digit))\n",
    "        n_label += n_digit\n",
    "    return n_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples to test the generator\n",
    "i = 0\n",
    "for a, b in generator(x_train, y_train, batch_size=16): \n",
    "    test_imgs = a\n",
    "    test_lbls = b\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzQAAANhCAYAAAAxMf4zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyENsb4eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e63cfdc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows_to_plot = 8\n",
    "cols_to_plot = 2\n",
    "\n",
    "f = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(16):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(convert_label(np.vstack((test_lbls[0][i], test_lbls[1][i], test_lbls[2][i], \n",
    "                                                test_lbls[3][i],test_lbls[4][i]))))\n",
    "    plt.imshow(test_imgs[i][:, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Model from: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf\n",
    "\n",
    "def get_model(input_shape=(28, 28*5, 3), p=0.5, n_class=11):\n",
    "\n",
    "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(48, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p/4)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(64, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p/4)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(128, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(160, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p)(x)\n",
    "    \n",
    "    # I had to remove this part because the input size we have is too small for a network this deep.\n",
    "    # Another alternative would have been change the maxpool strides.\n",
    "    \n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    #x = Dropout(p)(x)\n",
    "\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    #x = Dropout(p)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x) # I also reduced the number of activations\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    c1 = Dense(n_class, activation='softmax')(x)\n",
    "    c2 = Dense(n_class, activation='softmax')(x)\n",
    "    c3 = Dense(n_class, activation='softmax')(x)\n",
    "    c4 = Dense(n_class, activation='softmax')(x)\n",
    "    c5 = Dense(n_class, activation='softmax')(x)\n",
    "    \n",
    "    output = [c1, c2, c3, c4, c5]\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_output(model_output):\n",
    "    model_output = np.array(model_output).swapaxes(0, 1)\n",
    "    labels = []\n",
    "    for output in model_output:\n",
    "        label = convert_label(output)\n",
    "        labels.append(label)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(28, 28*5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 140, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 140, 1)   4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 140, 48)  1248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 70, 48)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 70, 48)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 70, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 70, 64)   76864       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 69, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 13, 69, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 69, 64)   256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, 69, 128)  204928      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 34, 128)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 34, 128)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6, 34, 128)   512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 34, 160)   512160      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 33, 160)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 5, 33, 160)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 5, 33, 160)   640         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 5, 33, 192)   768192      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 16, 192)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2, 16, 192)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 16, 192)   768         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 16, 192)   921792      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 15, 192)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 15, 192)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2880)         0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2950144     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 11)           11275       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,543,675\n",
      "Trainable params: 6,542,489\n",
      "Non-trainable params: 1,186\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit on small sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit small data to ensure model can learn\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer, loss='categorical_crossentropy')\n",
    "model.fit(test_imgs, test_lbls, epochs=50, verbose=0)\n",
    "teste_out = model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 8, not 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5d75d1e2871e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_to_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_to_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_subplots.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     raise ValueError(\n\u001b[1;32m     63\u001b[0m                         \"num must be 1 <= num <= {maxn}, not {num}\".format(\n\u001b[0;32m---> 64\u001b[0;31m                             maxn=rows*cols, num=num))\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 8, not 9"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAFrCAYAAAA0K4RcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKi07w5IkSSqt/wf1WQsaUM/oCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e5c0d85d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = convert_output(teste_out)\n",
    "\n",
    "rows_to_plot = 4\n",
    "cols_to_plot = 2\n",
    "\n",
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(\"Predicted: \" + pred)\n",
    "    plt.imshow(img[:, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(28, 28*5, 1))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "trn_generator = generator(x_train, y_train, batch_size=128)\n",
    "val_generator = generator(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "780/780 [==============================] - 6771s 9s/step - loss: 1.9798 - dense_10_loss: 0.4061 - dense_11_loss: 0.4776 - dense_12_loss: 0.4817 - dense_13_loss: 0.4037 - dense_14_loss: 0.2108 - dense_10_categorical_accuracy: 0.8546 - dense_11_categorical_accuracy: 0.8272 - dense_12_categorical_accuracy: 0.8281 - dense_13_categorical_accuracy: 0.8582 - dense_14_categorical_accuracy: 0.9307 - val_loss: 0.1840 - val_dense_10_loss: 0.0318 - val_dense_11_loss: 0.0461 - val_dense_12_loss: 0.0496 - val_dense_13_loss: 0.0360 - val_dense_14_loss: 0.0205 - val_dense_10_categorical_accuracy: 0.9930 - val_dense_11_categorical_accuracy: 0.9902 - val_dense_12_categorical_accuracy: 0.9892 - val_dense_13_categorical_accuracy: 0.9926 - val_dense_14_categorical_accuracy: 0.9958\n",
      "Epoch 2/2\n",
      "293/780 [==========>...................] - ETA: 56:51 - loss: 0.1915 - dense_10_loss: 0.0375 - dense_11_loss: 0.0461 - dense_12_loss: 0.0470 - dense_13_loss: 0.0385 - dense_14_loss: 0.0223 - dense_10_categorical_accuracy: 0.9905 - dense_11_categorical_accuracy: 0.9890 - dense_12_categorical_accuracy: 0.9879 - dense_13_categorical_accuracy: 0.9903 - dense_14_categorical_accuracy: 0.9940"
     ]
    }
   ],
   "source": [
    "model.fit_generator(trn_generator,\n",
    "                    epochs=2,\n",
    "                    steps_per_epoch=780,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=780,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test set with 1,000 examples\n",
    "\n",
    "i = 0\n",
    "for test_set, test_labels in generator(x_train, y_train, batch_size=1000): \n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = convert_output(test_pred)\n",
    "test_true_labels = convert_output(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 800\n",
    "print \"Predicted: \", test_pred_labels[ref]\n",
    "print \"Ground Truth: \", test_true_labels[ref]\n",
    "\n",
    "plt.imshow(test_set[ref][:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the individual predictions are above 99.5% for all digits, but the true error will be higher than that since any digit that we misclassify will be enough to render our prediction useless.\n",
    "\n",
    "So we need to evaluate the whole prediction as either right or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_true_labels, test_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Accuracy: \", accuracy*100, \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save  and load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('./models/step1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./models/step1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "Before I started coding the first step, it was good to think about the purpose of the synthetic dataset in the pipeline. Generally speaking, in an academic study, the datasets are somewhat standardized, and benchmarks for new models are established on top of this \"clean data\" - in commercial applications, however, that is not the norm. Labeled data to train your models are expensive to obtain, and the best approach is to often train a model in a similar dataset if available and then fine-tune it to the new problem you are trying to solve.\n",
    "\n",
    "Having said that, we want to make our synthetic data as close as possible to the data you expect to feed your model when you fine-tune it. So the obvious thing is to have a look at a few images from the SVHN dataset and then come up with a \"proxy\" synthetic dataset.\n",
    "\n",
    "Upon exploring the SVHN dataset we notice that the numbers are not always exactly centered, and they appear in several different colors, skew and rotation. \n",
    "\n",
    "Our synthetic dataset was created by first randomly choosing a number length between 1 and 5 digits, followed by another random decision as to where in the image we would like the sequence to appear (centered, skip first character, etc...) and then finally randomly pulling N digits from the MNIST training dataset.\n",
    "\n",
    "When creating the labels I decided to use \".\" to represent blank spaces to help when visually investigating the dataset.\n",
    "\n",
    "Examples were thoroughly provided on the notebook.\n",
    "\n",
    "\n",
    "** End-To-End Deep CNN model **\n",
    "\n",
    "In the project instructions there were several recommended approaches to create a pipeline to solve our problem, the one that I found more interesting is based on [[1]](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf \"Multi-digit Number Recognition from Street View\n",
    "Imagery using Deep Convolutional Neural Networks\") where the authors proposed an end-to-end solution to this problem that does not involve breaking down the problem into localization, segmentation and recognition in different steps.\n",
    "\n",
    "As Goodfellow et al. describe in their work:\n",
    ">Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery.\n",
    "Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels\n",
    "\n",
    "Inspired by the great results they displayed in their study and an elegant solution that would learn from these images without the assistance of a digit localizer, I decided to replicate their work for this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The model proposed by Goodfellow et al. is the following:\n",
    ">Our best architecture consists of eight convolutional hidden layers, one locally connected hidden layer, and two densely connected hidden layers. All connections are feedforward and go from one layer to the next (no skip connections). The first hidden layer contains maxout units (Goodfellow et al., 2013) (with three filters per unit) while the others contain rectifier units (Jarrett et al., 2009; Glorot et al., 2011). The number of units at each spatial location in each layer is [48, 64, 128, 160] for the first four layers and 192 for all other locally connected layers. The fully connected layers contain 3,072 units each.\n",
    "\n",
    "\n",
    "The dimensions of our synthetic images are 28 x 140 x 1 (MNIST dimensions are 28 x 28 and we concatenated up to 5 of them together) and the 11 layer the authors used in their work was too deep for our data, so some modification was needed.\n",
    "\n",
    "I could have just removed a few of the MaxPooling layers, but since this problem was simpler to solve I decided to completely remove the last two convolutional blocks and the first locally connected hidden layer. I also included BatchNormalization before every convolutional layer and reduced the number of activations on the fully connected layers to 1024.\n",
    "\n",
    "The final version can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The first step was to create a function that would output an image of up to 5 digits, randomly extracted from the MNIST dataset and it's label - For the sake of visualization I decided to use a \".\" to represent blank cells, that way we can validate if the position of the prediction is in the right place. The full implementation can be found in this notebook, under the function **create_numbers**.\n",
    "\n",
    "The next step was to create a python generator that would output several of these images and their labels in a format that Keras API would be able to process. This can be found under the function **generator** provided above.\n",
    "\n",
    "The python generator leverages the **create_numbers** function in order to provide us with a virtually unlimited training set. A thorough explanation of how it works can be seen below:\n",
    "\n",
    "```python\n",
    "def generator(numbers, number_labels, batch_size=32):\n",
    "\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "    \n",
    "        # define blank lists that will be filled in the for loop\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # loop for as many iterations as you want your batch size to be\n",
    "        for batch_sample in range(batch_size):\n",
    "            img, label = create_numbers(numbers, number_labels, return_label=True)\n",
    "            \n",
    "            # After calling our create_numbers function we are basically done, but unfortunately\n",
    "            # Keras needs the labels to be one-hot encoded so from here on we just convert\n",
    "            # our labels into arrays of n_label dimensions that has 1 for the column to which class\n",
    "            # the sample belongs and 0 everywhere else.\n",
    "            \n",
    "            # define a label set with 5 rows (number of digits) and 11 columns (0-9 digits + blank)\n",
    "            n_label = np.zeros((5, 11), dtype='int')\n",
    "            for i, digit in enumerate(label):\n",
    "                if digit == \".\":\n",
    "                    n_digit = 10\n",
    "                else:\n",
    "                    n_digit = int(digit)\n",
    "\n",
    "                n_label[i][n_digit] = 1\n",
    "                \n",
    "        # in the function we manipulate the numbers furter to ensure compatibility with Keras' API \n",
    "\n",
    "        # return randomly generated image and list of one-hot encoded labels\n",
    "        yield X_train, [y1, y2, y3, y4, y5]\n",
    "```\n",
    "\n",
    "Samples were provided right after each function was created.\n",
    "\n",
    "With this generator we can have an unlimited amount of data to train our model. My first step was to train the model with a very small dataset (8 samples) that allowed me to quickly identify mistakes and fix the model without the burden of waiting for the long training time. At this stage I also made sure the model could overfit the small sample.\n",
    "\n",
    "When you have unlimited training data, the only problem you need to worry about is for how long to train. In general, it's difficult to end up over fitting to your data if your synthetic data is carefully crafted like ours.\n",
    "\n",
    "I used a mini-batch size of 128 samples, a number large enough that also fit in my GPU memory, and decided that every epoch should consist of approximately 100k images (as it would in theory allow the model to see each possibility at least once, although in practice we can't be sure) after just two epochs of training our validation accuracy was already above 99.5% for each individual digit so I stopped training.\n",
    "\n",
    "Measuring accuracy in that way is not recommended, because if our output has any of the digits wrong, the information is useless. So I converted the predicted digits back to string and compared with the ground truth strings generated for 1,000 random images from the validation set and the accuracy this time was 98.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bruno/Documents/eLearning/udacity/Digit-Recognition'\n",
    "dataset_path = '/media/bruno/Data/Datasets/SVHN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = glob(dataset_path + '/train/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_plot = 5\n",
    "cols_to_plot = 5\n",
    "\n",
    "f = plt.figure(figsize=(16, 4))\n",
    "\n",
    "for i, fn in enumerate(np.random.choice(len(train_filenames), rows_to_plot * cols_to_plot)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.imshow(Image.open(train_filenames[fn], mode='r'))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first exploration we can see that it's going to be a lot harder to train a model that performs well on this dataset. The numbers appear in different colors, distortions, skews and conditions (e.g. blurred images).\n",
    "\n",
    "Differently than our synthetic dataset, street numbers in real life don't have a random distribution like the ones we created. Most streets are short ones and we should expect to see a lot more numbers with less 3 or less digits than with 4 or 5.\n",
    "\n",
    "Let's take a look at how the length of digits is distributed in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndSaveMetadata(filepath):\n",
    "    # Forked from https://discussions.udacity.com/t/how-to-deal-with-mat-files/160657/3\n",
    "    \n",
    "    # Load the given MatLab file\n",
    "    f = h5py.File(filepath, 'r')\n",
    "    fn = filepath.split('/')[-1]\n",
    "    \n",
    "    # Create our empty dictionary\n",
    "    metadata= {}\n",
    "    metadata['height'] = []\n",
    "    metadata['label'] = []\n",
    "    metadata['left'] = []\n",
    "    metadata['top'] = []\n",
    "    metadata['width'] = []\n",
    "    \n",
    "    # define a function to pass to h5py's visititems() function\n",
    "    def print_attrs(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(f[obj[k][0]][0][0])\n",
    "        metadata[name].append(vals)\n",
    "    \n",
    "    # Add information to metadata\n",
    "    for item in f['/digitStruct/bbox']:\n",
    "        f[item[0]].visititems(print_attrs)\n",
    "    \n",
    "    # Save to a pickle file\n",
    "    pickle_file = fn + '.pickle'\n",
    "    try:\n",
    "      pickleData = open(pickle_file, 'wb')\n",
    "      pickle.dump(metadata, pickleData, pickle.HIGHEST_PROTOCOL)\n",
    "      pickleData.close()\n",
    "    except Exception as e:\n",
    "      print 'Unable to save data to', pickle_file, ':', e\n",
    "      raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readAndSaveMetadata(dataset_path + 'train_digitStruct.mat')\n",
    "#readAndSaveMetadata(dataset_path + 'test_digitStruct.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train_digitStruct.mat.pickle', 'r')\n",
    "trn_data = pickle.load(f)\n",
    "trn_data = pd.DataFrame.from_dict(trn_data)\n",
    "\n",
    "f = open('test_digitStruct.mat.pickle', 'r')\n",
    "tst_data = pickle.load(f)\n",
    "tst_data = pd.DataFrame.from_dict(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_label_len = []\n",
    "for label in trn_data['label']:\n",
    "    label_len = len(label)\n",
    "    trn_label_len.append(label_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, bins, patches = plt.hist(trn_label_len, bins=range(1,7), normed=True )\n",
    "\n",
    "plt.plot(np.concatenate(([0], np.cumsum(count))), 'r' )\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('House Number Length Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected over 95% of our sample has 3 or less digits. This will probably impact the performance of our algorithm when detecting longer street numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image pre-processing\n",
    "\n",
    "The authors of the paper we are basing this work on have suggested the following pre-processing steps:\n",
    "\n",
    "- Based on the provided bounding boxes, find another box that will contain all digits on the image\n",
    "\n",
    "- Expand this bounding box by 30% in each direction and crop the image to this bounding box\n",
    "\n",
    "- Resize the cropped image to 64 x 64 pixels\n",
    "\n",
    "- Random crop a 54 x 54 sample from the cropped image\n",
    "\n",
    "This will be implemented inside a generate_crop function that will later on be called by our generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_crop(filepath, dataframe, expand_by=0.3, verbose=0, crop_sz=(64, 64), random_crop=True):\n",
    "    \"\"\"\n",
    "    This function expects a filepath of an image and will return either a 64 x 64 crop\n",
    "    or a 54 x 54 random crop of the street number depending on the random_crop parameter.\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1 - open the image and store img dimensions\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_h = img.shape[0]\n",
    "    img_w = img.shape[1]\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"img_h: \", img_h, \"    img_w: \", img_w, \"\\n\"\n",
    "\n",
    "    # 2 - find bounding box for whole street number\n",
    "    fn = filepath.split('/')[-1].split('.')[0]\n",
    "\n",
    "    left = np.min(dataframe.loc[int(fn) - 1].left)\n",
    "    top = np.min(dataframe.loc[int(fn) - 1].top)\n",
    "    bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height))\n",
    "    right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width))\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
    "\n",
    "    # 3 - Expand bounding box by X%\n",
    "    mid_x = (left + right) // 2\n",
    "    mid_y = (top + bottom) // 2\n",
    "    new_h = np.abs(bottom - top) * (1 + expand_by)\n",
    "    new_w = np.abs(right - left) * (1 + expand_by)\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"mid_x: \", mid_x, \"    mid_y: \", mid_y, \"    new_h: \", new_h, \"    new_w: \", new_w, \"\\n\"\n",
    "    \n",
    "    # New points will be determined by the calculations above and the original image size\n",
    "    left = np.max((0, mid_x - new_w // 2)).astype(np.uint)\n",
    "    right = np.min((img_w, mid_x + new_w // 2)).astype(np.uint)\n",
    "    top = np.max((0, mid_y - new_h // 2)).astype(np.uint)\n",
    "    bottom = np.min((img_h, mid_y + new_h // 2)).astype(np.uint)\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"n_left: \", left, \"    n_right: \", right, \"    n_top: \", top, \"    n_bottom: \", bottom, \"\\n\"\n",
    "    \n",
    "    # 4 - Crop image within bounding box\n",
    "    cropped = img[top:bottom, left:right, :].copy()\n",
    "\n",
    "    # 5 - Rescale to 64 x 64\n",
    "    rescaled = cv2.resize(cropped, crop_sz)\n",
    "    \n",
    "    if random_crop:\n",
    "        dx = np.random.randint(0, 10)\n",
    "        dy = np.random.randint(0, 10)\n",
    "        rescaled = rescaled[dx:dx+54, dy:dy+54, :]\n",
    "    \n",
    "    return rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_plot = 10\n",
    "\n",
    "f = plt.figure(figsize=(12, 12))\n",
    "\n",
    "i = 0\n",
    "for fn in np.random.choice(len(train_filenames), items_to_plot):\n",
    "    # Plot original\n",
    "    f.add_subplot(items_to_plot // 2, 4, i+1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(Image.open(train_filenames[fn], mode='r'))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "    # Plot cropped\n",
    "    f.add_subplot(items_to_plot // 2, 4, i+1)\n",
    "    plt.title('Random Crop')\n",
    "    plt.imshow(generate_crop(train_filenames[fn], trn_data))\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run with the previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can isolate the numbers from the rest of the image, we can pass this image to our first model and see how it performs. In order to do that we will need to scale them to 28 x 140 and grayscale - since this is how our model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = generate_crop(train_filenames[35], trn_data, crop_sz=(140, 28), random_crop=False)\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(test_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.expand_dims(test_img, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(np.expand_dims(test_img, 0))\n",
    "test_pred_labels = convert_output(test_pred)\n",
    "print \"Predicted: \", test_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 35\n",
    "test_img = generate_crop(train_filenames[ref], trn_data, crop_sz=(140, 28), random_crop=False)\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY)\n",
    "test_img = np.expand_dims(test_img, -1)\n",
    "test_pred = model.predict(np.expand_dims(test_img, 0))\n",
    "test_pred_labels = convert_output(test_pred)\n",
    "\n",
    "plt.imshow(test_img[:, :, 0], cmap='gray')\n",
    "plt.title(\"Predicted label: \" + test_pred_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a good indicator, I personally chose the above image as i expected it to be easier, as it's somewhat similar to what we have been using so far. Unfortunately because the two datasets have labels created in very different ways, it would be too time consuming to develop a compatibility layer just to prove that our current model is not doing a good job.\n",
    "\n",
    "If we had reasons to believe it would perform well, it would probably be worth to invest time into doing that, but if it fails on the \"easy\" images, we will make a better use of our time if we train a new model.\n",
    "\n",
    "The paper we are basing our work on trains the model using not only the 5 digits, but also the length of the digits, we will now define a function to get us this information for each sample in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath, dataframe, maxlength=5):\n",
    "    \"\"\"\n",
    "\n",
    "    This function will return the categorical (one-hot) representation of 6 digits \n",
    "    that will be used to train our model.\n",
    "    \n",
    "    The first is the length of the house number for a given filepath and then one digit\n",
    "    for each of the 5 possible spots we are trying to predict, with 0 being \"more than 5\" for length\n",
    "    and blank for the individual digits.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    fn = filepath.split('/')[-1].split('.')[0]\n",
    "\n",
    "    label = dataframe.loc[int(fn) - 1].label\n",
    "\n",
    "    l = np.zeros(maxlength+1)\n",
    "    try:\n",
    "        l[len(label)] = 1\n",
    "    except:\n",
    "        l[0] = 1\n",
    "\n",
    "    y = np.zeros((5, 11), dtype=int)\n",
    "\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            y[i][int(label[i])] = 1\n",
    "        except:\n",
    "            y[i][0] = 1\n",
    "\n",
    "    return [l, y[0], y[1], y[2], y[3], y[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define a new function to convert back our label to a format we can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_convert_label(label):\n",
    "    l = label[0]\n",
    "    labels = label[1:]\n",
    "    n_label = \"\"\n",
    "    for digit in labels:\n",
    "        if np.argmax(digit) == 0:\n",
    "            n_digit = \"\"\n",
    "        elif np.argmax(digit) == 10:\n",
    "            n_digit = \"0\"\n",
    "        else:\n",
    "            n_digit = str(np.argmax(digit))\n",
    "        n_label += n_digit\n",
    "    return n_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if everything works\n",
    "# print (get_label(train_filenames[100], trn_data))\n",
    "print \"converted label: \", new_convert_label(get_label(train_filenames[10], trn_data))\n",
    "plt.imshow(generate_crop(train_filenames[10], trn_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Generator\n",
    "\n",
    "Similarly to what we did on the first step, we will define a generator that will pass a random crop of the image and all the labels to our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_generator(filepath_list, dataframe, batch_size=32, crop_sz=(64, 64),\n",
    "                  shuffle_data=True, random_crop=True, return_labels=True):\n",
    "    \"\"\"\n",
    "    This generator receives a lisit of filenames from the SVHN dataset and a pandas dataframe\n",
    "    with the label information and returns a random crop of the image and the one-hot encoding\n",
    "    of the labels so we can pass it directly to Keras.\n",
    "\n",
    "    Input:\n",
    "    filepath_list - list with path to SVHN images.\n",
    "    dataframe - pandas dataframe with information about each image.\n",
    "\n",
    "    Arguments:\n",
    "    batch_size - size of the mini batch\n",
    "\n",
    "    Outputs:\n",
    "    X_train and y_train\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = len(filepath_list)\n",
    "    filelist = copy.copy(filepath_list)\n",
    "\n",
    "    if shuffle_data:\n",
    "        shuffle(filelist)\n",
    "\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = filelist[offset:offset + batch_size]\n",
    "\n",
    "            if shuffle_data:\n",
    "                shuffle(batch_samples)\n",
    "\n",
    "            images = []\n",
    "            length = []\n",
    "            digits = []\n",
    "\n",
    "            for batch_sample in batch_samples:\n",
    "                img = generate_crop(batch_sample, dataframe, crop_sz=crop_sz, random_crop=random_crop)\n",
    "                y = np.zeros((5, 11), dtype='int')\n",
    "                [l, y[0, :], y[1, :], y[2, :], y[3, :], y[4, :]] = get_label(batch_sample, dataframe)\n",
    "            \n",
    "                images.append(img)\n",
    "                length.append(l)\n",
    "                digits.append(y)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            if len(X_train.shape) == 3:\n",
    "                X_train = np.expand_dims(X_train, -1)\n",
    "\n",
    "            y_temp = np.array(digits)\n",
    "            l = np.array(length)\n",
    "\n",
    "            y1 = y_temp[:, 0, :]\n",
    "            y2 = y_temp[:, 1, :]\n",
    "            y3 = y_temp[:, 2, :]\n",
    "            y4 = y_temp[:, 3, :]\n",
    "            y5 = y_temp[:, 4, :]\n",
    "            \n",
    "            if return_labels:\n",
    "                yield X_train, [l, y1, y2, y3, y4, y5]\n",
    "            else:\n",
    "                yield X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples to test the generator\n",
    "i = 0\n",
    "for a, b in new_generator(train_filenames, trn_data, batch_size=25): \n",
    "    test_imgs = a\n",
    "    test_lbls = b\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_plot = 5\n",
    "cols_to_plot = 5\n",
    "\n",
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(rows_to_plot * cols_to_plot):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(new_convert_label([test_lbls[0][i], test_lbls[1][i], test_lbls[2][i], \n",
    "                                 test_lbls[3][i], test_lbls[4][i], test_lbls[5][i]]))\n",
    "    plt.imshow(test_imgs[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "This time we can define the model exactly as proposed on the literature, given that our input images are also with the same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Model from: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf\n",
    "\n",
    "def get_new_model(input_shape=(54, 54, 3), p=0.5, n_class=11, n_len=6):\n",
    "\n",
    "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
    "    \n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Convolution2D(48, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p/4)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(64, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p/4)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(128, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(160, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(p)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(192, 5, activation='relu', padding='same', strides=(1, 1))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(x)\n",
    "    x = Dropout(p)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(3072, activation='relu')(x)\n",
    "    x = Dense(3072, activation='relu')(x)\n",
    "\n",
    "    l = Dense(n_len, activation='softmax')(x)\n",
    "    c1 = Dense(n_class, activation='softmax')(x)\n",
    "    c2 = Dense(n_class, activation='softmax')(x)\n",
    "    c3 = Dense(n_class, activation='softmax')(x)\n",
    "    c4 = Dense(n_class, activation='softmax')(x)\n",
    "    c5 = Dense(n_class, activation='softmax')(x)\n",
    "    \n",
    "    output = [l, c1, c2, c3, c4, c5]\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = get_new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_convert_output(model_output):\n",
    "    l = model_output[0]\n",
    "    digits = np.array(model_output[1:]).swapaxes(0, 1)\n",
    "    labels = []\n",
    "    for i in range(len(l)):\n",
    "        label = new_convert_label(([l[i]], digits[i, 0, :], digits[i, 1, :],\n",
    "                                  digits[i, 2, :], digits[i, 3, :], digits[i, 4, :]))\n",
    "        labels.append(label)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit new model on small sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "new_model.compile(optimizer, loss='categorical_crossentropy')\n",
    "new_model.fit(test_imgs, test_lbls, epochs=1000, verbose=0)\n",
    "teste_out = new_model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = new_convert_output(teste_out)\n",
    "\n",
    "rows_to_plot = 5\n",
    "cols_to_plot = 5\n",
    "\n",
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(\"Predicted: \" + pred)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the model required 1,000 epochs on the sample dataset to get to a \"reasonable\" point. It's still not overfitting completely, but it's learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation, using 80% for training and 20% for validation:\n",
    "trn_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = get_new_model()\n",
    "optimizer = Adam(lr=1e-3)\n",
    "new_model.compile(optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "callbacks = [ModelCheckpoint('./models/new_model.{epoch:02d}-{val_loss:.2f}.hdf5')]\n",
    "\n",
    "trn_generator = new_generator(trn_filenames, trn_data, batch_size=128)\n",
    "val_generator = new_generator(val_filenames, trn_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit_generator(trn_generator,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=200,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=200,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save  and load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.save_weights('./models/step2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.load_weights('./models/step2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_out = new_model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = new_convert_output(teste_out)\n",
    "\n",
    "rows_to_plot = 5\n",
    "cols_to_plot = 5\n",
    "\n",
    "f = plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, (pred, img) in enumerate(zip(output, test_imgs)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(\"Predicted: \" + pred)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_filenames = glob(dataset_path + '/test/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_imgs = []\n",
    "tst_labels = []\n",
    "for filename in tst_filenames:\n",
    "    img = generate_crop(filename, tst_data, crop_sz=(54, 54), random_crop=False)\n",
    "    lbl = get_label(filename, tst_data)\n",
    "    n_lbl = new_convert_label(lbl)\n",
    "    tst_labels.append(n_lbl)\n",
    "    tst_imgs.append(img)\n",
    "\n",
    "tst_imgs = np.array(tst_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we are getting the imgs and labels correctly\n",
    "rows_to_plot = 5\n",
    "cols_to_plot = 5\n",
    "\n",
    "f = plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i, fn in enumerate(np.random.choice(len(tst_filenames), rows_to_plot * cols_to_plot)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.imshow(tst_imgs[fn])\n",
    "    plt.title(tst_labels[fn])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst_generator = new_generator(tst_filenames, tst_data, batch_size=128, crop_sz=(54, 54),\n",
    "#                              shuffle_data=False, random_crop=False, return_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tst_pred = new_model.predict_generator(tst_generator, steps=len(tst_filenames) // 128 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_pred = new_model.predict(tst_imgs, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = new_convert_output(tst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_accuracy = accuracy_score(tst_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Accuracy: \", np.round(tst_accuracy*100, 1), \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still significantly below the 98% of human accuracy, but in Goodfellow et al. they trained 10 models in parallel for 6 days to achieve human level accuracy. Our version was trained for 20 epochs, where in each epoch it would see approximately 10 different crops of each image.\n",
    "\n",
    "If we continued to optimize the model weights, I am positive we would have better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "### Testing the first model on the SVHN dataset\n",
    "\n",
    "At this point I realized that I should have also explored the labels from the SVHN dataset and not only the images when creating our synthetic dataset.\n",
    "\n",
    "The fact that the labels were incompatible made large-scaling impossible without developing a label-conversion function and before doing that I decided to manually test the model in a few selected images to see if it was worth investing the time to convert the labels.\n",
    "\n",
    "The only processing steps on the new images were to scale to 28 x 140 pixels and convert to gray scale, as that is how our model was trained.\n",
    "\n",
    "Surprisingly the model was not able to generalize at all, it was incorrect on 100% of the test images. I was obviously expecting a decrease in performance but 0% accuracy was definitely an unpleasant surprise.\n",
    "\n",
    "Due to the incompatibility of labels and input size between datasets, fine tuning would be more difficult than training a new model. Too bad, as we ended up missing an important part of the purpose of the synthetic dataset, although all this was not completely wasted, we validated that the model architecture we chose is right for the problem at hand.\n",
    "\n",
    "### Training 2.0\n",
    "\n",
    "The SVHN data set provides coordinates of bounding boxes for each digit in an image, but since the purpose of our pipeline is to identify the whole street number in one shot, we needed to pass a cropped version of the image with all numbers in it, and not much more.\n",
    "\n",
    "We followed the suggested training methodology from Goodfellow et al.\n",
    "\n",
    "- Based on the provided bounding boxes, find another box that will contain all digits on the image\n",
    "\n",
    "- Expand this bounding box by 30% in each direction and crop the image to this bounding box\n",
    "\n",
    "- Resize the cropped image to 64 x 64 pixels\n",
    "\n",
    "- Random crop a 54 x 54 sample from the cropped image\n",
    "\n",
    "Training was again assisted by a python generator, that randomly cropped the 64 x 64 pixel image into 54 x 54 patches, aiming to increase the amount of training data. At this time 20% of the dataset was put aside for validation.\n",
    "\n",
    "The accuracy of the model on a realistic dataset is 83%, but the accuracy was still improving when we decided to interrupt the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Knowing that we would need to train a new model from scratch gave me the freedom to implement some improvements to the architecture. I added back to the model the two convolutional blocks that were initially removed, I also increased the number of hidden units in the last two fully connected layers and added a new branch of softmax classifier to predict the length of the sequence of digits.\n",
    "\n",
    "Aside from these few adjustments, the model architecture is very similar to our first one and can be seen below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(new_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "My initial result was probably very close to 0, as I tried to use the pre-trained weights of my model on step 1, but didn't have an easy way of converting the labels of the second dataset to measure it's performance. Since the initial exploration was already indicating that it would have a poor performance, I decided to train a larger model, following the suggestion of the literature we based this work on.\n",
    "\n",
    "At the end of 20 epochs the accuracy of our model was 83% - still significantly below human accuracy, but it is a strong indicator that the model is able to learn and if trained for longer, it could achieve results similar to what was observed by the authors of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = []\n",
    "new_filenames = []\n",
    "\n",
    "filelist = os.listdir('./data/')\n",
    "\n",
    "for file in filelist:\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        img = None\n",
    "\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (54, 54))\n",
    "        new_images.append(img)\n",
    "        new_filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = np.array(new_images)\n",
    "test_new_preds = new_model.predict(new_images)\n",
    "new_pred_labels = new_convert_output(test_new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows_to_plot = 5\n",
    "cols_to_plot = 2\n",
    "\n",
    "f = plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i, (pred, img) in enumerate(zip(new_pred_labels, new_images)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(\"Predicted: \" + pred)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now pass on the cropped numbers to see if it gets any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = []\n",
    "new_filenames = []\n",
    "\n",
    "filelist = os.listdir('./data/small/')\n",
    "\n",
    "for file in filelist:\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread('./data/small/' + file, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        img = None\n",
    "\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (54, 54))\n",
    "        new_images.append(img)\n",
    "        new_filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = np.array(new_images)\n",
    "test_new_preds = new_model.predict(new_images)\n",
    "new_pred_labels = new_convert_output(test_new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_plot = 5\n",
    "cols_to_plot = 2\n",
    "\n",
    "f = plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i, (pred, img) in enumerate(zip(new_pred_labels, new_images)):\n",
    "    f.add_subplot(rows_to_plot, cols_to_plot, i+1)\n",
    "    plt.title(\"Predicted: \" + pred)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The pictures were taking from a long distance, and when they were scaled down the algorithm failed to predict in all 5 cases. When we passed the cropped number it actually had a performance similar to what we found above ~80% (4 out of 5 numbers were correctly labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Our model only performed well when the images were cropped in a similar way as the images we passed on to the model during training. Which is in line with what should be expected. We trained the model using an easier dataset where the numbers were already located for it and it's unreasonable to expect that the model would be able to generalize to images with a lot more information.\n",
    "\n",
    "Another issue is that we trained the model on a super small patch of image 54 x 54 pixels, and to use an image that was captured with a smartphone we needed to downsize it so much that any detail was lost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bounding boxes to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(filepath, dataframe, verbose=0):\n",
    "    \"\"\"\n",
    "    This function expects a filepath of an image and a dataframe with information for the bounding boxes\n",
    "    and will return a larger bounding box that wraps all the digits on the house number.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # 1 - find bounding box for whole street number\n",
    "    fn = filepath.split('/')[-1].split('.')[0]\n",
    "\n",
    "    left = np.min(dataframe.loc[int(fn) - 1].left).astype(np.uint)\n",
    "    top = np.min(dataframe.loc[int(fn) - 1].top).astype(np.uint)\n",
    "    bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height)).astype(np.uint)\n",
    "    right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width)).astype(np.uint)\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
    "\n",
    "    \n",
    "    return left, right, top, bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[0], bb[2]), bb[1] - bb[0], bb[3] - bb[2], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb_raw(filepath, dataframe):\n",
    "    bb = get_bbox(filepath, dataframe)\n",
    "    plt.imshow(Image.open(filepath, mode='r'))\n",
    "    plt.gca().add_patch(create_rect(bb))\n",
    "\n",
    "def show_bb(img, bb, bb_2=None):\n",
    "    plt.imshow(img)\n",
    "    plt.gca().add_patch(create_rect(bb))\n",
    "    if bb_2 is not None:\n",
    "        plt.gca().add_patch(create_rect(bb_2, 'yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bb_raw(val_filenames[5587], trn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling images and bounding boxes\n",
    "\n",
    "Since we have images with various dimensions, we will need to rescale them to the same size in order to feed our model. We will also need to apply the same transformation to the bounding boxes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgs(filepath, dataframe, return_bbox=True, target_sz=(64, 64), verbose=0):\n",
    "\n",
    "    # 1 - open the image and store img dimensions\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_h = float(img.shape[0])\n",
    "    img_w = float(img.shape[1])\n",
    "\n",
    "    if verbose>0:\n",
    "        print \"img_h: \", img_h, \"    img_w: \", img_w, \"\\n\"\n",
    "        print \"tgt_sz_0: \", target_sz[0], \"    tgt_sz_1: \", target_sz[1], \"\\n\"\n",
    "\n",
    "    # 2 - resize image\n",
    "    rescaled = cv2.resize(img, target_sz)\n",
    "    \n",
    "    if return_bbox:\n",
    "\n",
    "        # 3 - find bounding box for whole street number\n",
    "        fn = filepath.split('/')[-1].split('.')[0]\n",
    "\n",
    "        left = np.min(dataframe.loc[int(fn) - 1].left)\n",
    "        top = np.min(dataframe.loc[int(fn) - 1].top)\n",
    "        bottom = (np.max(dataframe.loc[int(fn) - 1].top) + np.max(dataframe.loc[int(fn) - 1].height))\n",
    "        right = (np.max(dataframe.loc[int(fn) - 1].left) + np.max(dataframe.loc[int(fn) - 1].width))\n",
    "        \n",
    "        if verbose>0:\n",
    "            print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
    "\n",
    "        # 4 - Convert bounding box to new image size\n",
    "        h_ratio = img_h / target_sz[0]\n",
    "        w_ratio = img_w / target_sz[1]\n",
    "\n",
    "        if verbose>0:\n",
    "            print \"h_ratio: \", h_ratio, \"    w_ratio: \", w_ratio, \"\\n\"\n",
    "        \n",
    "        left = np.max((0, np.floor_divide(left, w_ratio)))\n",
    "        right = np.min((target_sz[1], np.floor_divide(right, w_ratio)))\n",
    "        top = np.max((0, np.floor_divide(top, h_ratio)))\n",
    "        bottom = np.min((target_sz[0], np.floor_divide(bottom, h_ratio)))\n",
    "\n",
    "        if verbose>0:\n",
    "            print \"left: \", left, \"    right: \", right, \"    top: \", top, \"    bottom: \", bottom, \"\\n\"\n",
    "\n",
    "        return rescaled, [left, right, top, bottom]\n",
    "\n",
    "    else:\n",
    "        return rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"trn_bbox_imgs = []\n",
    "trn_bbox_box = []\n",
    "target_sz = (64, 64)\n",
    "\n",
    "for filename in trn_filenames:\n",
    "    img, bb = resize_imgs(filename, trn_data, target_sz=(64, 64), verbose=0)\n",
    "    trn_bbox_imgs.append(img)\n",
    "    trn_bbox_box.append(bb)\n",
    "\n",
    "trn_bbox_box = np.array(trn_bbox_box)\n",
    "trn_bbox_imgs = np.array(trn_bbox_imgs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"val_bbox_imgs = []\n",
    "val_bbox_box = []\n",
    "target_sz = (64, 64)\n",
    "\n",
    "for filename in val_filenames:\n",
    "    img, bb = resize_imgs(filename, trn_data, target_sz=(64, 64), verbose=0)\n",
    "    val_bbox_imgs.append(img)\n",
    "    val_bbox_box.append(bb)\n",
    "\n",
    "val_bbox_box = np.array(val_bbox_box)\n",
    "val_bbox_imgs = np.array(val_bbox_imgs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save images and bboxes to pickle\n",
    "f = open('trn_filenames.pickle', 'wb')\n",
    "pickle.dump(trn_filenames, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "f = open('val_filenames.pickle', 'wb')\n",
    "pickle.dump(val_filenames, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "f = open('trn_bbox_box.pickle', 'wb')\n",
    "pickle.dump(trn_bbox_box, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "f = open('trn_bbox_imgs.pickle', 'wb')\n",
    "pickle.dump(trn_bbox_imgs, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "f = open('val_bbox_box.pickle', 'wb')\n",
    "pickle.dump(val_bbox_box, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "f = open('val_bbox_imgs.pickle', 'wb')\n",
    "pickle.dump(val_bbox_imgs, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pickles\n",
    "f = open('trn_filenames.pickle', 'r')\n",
    "trn_filenames = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('val_filenames.pickle', 'r')\n",
    "val_filenames = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('trn_bbox_box.pickle', 'r')\n",
    "trn_bbox_box = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('trn_bbox_imgs.pickle', 'r')\n",
    "trn_bbox_imgs = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('val_bbox_box.pickle', 'r')\n",
    "val_bbox_box = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('val_bbox_imgs.pickle', 'r')\n",
    "val_bbox_imgs = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "trn_bbox_box = np.array(trn_bbox_box, dtype=float)\n",
    "trn_bbox_imgs = np.array(trn_bbox_imgs, dtype=float)\n",
    "val_bbox_box = np.array(val_bbox_box, dtype=float)\n",
    "val_bbox_imgs = np.array(val_bbox_imgs, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_bbox(bbox):\n",
    "    \"\"\"\n",
    "    Input: bounding box: Left, Right, Top, Bottom\n",
    "    Output: x0, y0, width, height\n",
    "    \"\"\"\n",
    "    \n",
    "    left, right, top, bottom = bbox\n",
    "    \n",
    "    x0 = left\n",
    "    y0 = top\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "    \n",
    "    return x0, y0, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_bbox_box_new = [cvt_bbox(box) for box in trn_bbox_box]\n",
    "trn_bbox_imgs /= 255\n",
    "trn_bbox_imgs -= 0.5\n",
    "\n",
    "#val_bbox_box_new  = [cvt_bbox(box) for box in val_bbox_box]\n",
    "val_bbox_imgs /= 255\n",
    "val_bbox_imgs -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=777\n",
    "show_bb(trn_bbox_imgs[ref], trn_bbox_box[ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First attempt: Use the image and the coordinates of the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(((64, 64, 3)))\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Convolution2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x_bb = Dense(4, name='bb')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model = Model([inputs], x_bb,)\n",
    "loc_model.compile(Adam(lr=0.001), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model.fit(trn_bbox_imgs[0:5], trn_bbox_box[0:5], batch_size=5, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loc_model.history.history['loss'], '-o')\n",
    "plt.legend(['trn_loss'], loc='upper right')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model = Model([inputs], x_bb,)\n",
    "loc_model.compile(Adam(lr=0.001), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model.fit(trn_bbox_imgs, trn_bbox_box, batch_size=32, epochs=5,\n",
    "              validation_data=(val_bbox_imgs, val_bbox_box), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loc_model.history.history['loss'], '-o')\n",
    "plt.plot(loc_model.history.history['val_loss'], '-o')\n",
    "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box = loc_model.predict(val_bbox_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ref=8\n",
    "show_bb((val_bbox_imgs[val_ref] + 0.5) * 255, val_bbox_box[val_ref], pred_box[val_ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second attempt: Transform bounding boxes into image masks and use a better loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_seg(img, bbox, value=1.):\n",
    "    \n",
    "    img_mask = np.zeros_like(img[:,:,0])\n",
    "    \n",
    "    x_min, x_max, y_min, y_max = bbox\n",
    "    \n",
    "    x_min = np.round(x_min,0).astype(np.uint8)\n",
    "    x_max = np.round(x_max,0).astype(np.uint8)\n",
    "    y_min = np.round(y_min,0).astype(np.uint8)\n",
    "    y_max = np.round(y_max,0).astype(np.uint8)\n",
    "\n",
    "    img_mask[y_min:y_max, x_min:x_max]= 1. * value\n",
    "\n",
    "    img_mask = np.reshape(img_mask,(np.shape(img_mask)[0],np.shape(img_mask)[1],1))\n",
    "    \n",
    "    return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_im_mask(im,im_mask):\n",
    "    ### Function to plot image mask \n",
    "    \n",
    "    im = np.array(im,dtype=np.uint8)\n",
    "    im_mask = np.array(im_mask,dtype=np.uint8)\n",
    "    plt.figure(figsize=(24,12))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(im_mask[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.bitwise_and(im,im,mask=im_mask));\n",
    "    plt.axis('off')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_trn_mask = np.array([get_mask_seg(img,bbox, value=1.) for (img,bbox) in zip(trn_bbox_imgs, trn_bbox_box) ])\n",
    "\n",
    "loc_val_mask = np.array([get_mask_seg(img,bbox, value=1.) for (img,bbox) in zip(val_bbox_imgs, val_bbox_box) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 777\n",
    "plot_im_mask(trn_bbox_imgs[ref], loc_trn_mask[ref] * 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IOU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IOU or dice coeff calculation measures the similarity in both area and position of the two bounding boxes\n",
    "\n",
    "def IOU_calc(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def IOU_loss(y_true, y_pred):\n",
    "    return -IOU_calc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = Input(((64, 64, 3)))\n",
    "\n",
    "x = BatchNormalization()(inputs2)\n",
    "x = Convolution2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output2 = Convolution2D(1, 3, activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model2 = Model([inputs2], output2,)\n",
    "loc_model2.compile(Adam(lr=0.001), loss=IOU_loss, metrics=[IOU_calc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfit small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model2.fit(trn_bbox_imgs[0:5], loc_trn_mask[0:5], batch_size=5, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loc_model2.history.history['loss'], '-o')\n",
    "plt.legend(['trn_loss'], loc='upper right')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model2 = Model([inputs2], output2,)\n",
    "loc_model2.compile(Adam(lr=0.001), loss=IOU_loss, metrics=[IOU_calc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model2.fit(trn_bbox_imgs, loc_trn_mask, batch_size=32, epochs=2,\n",
    "              validation_data=(val_bbox_imgs, loc_val_mask), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loc_model2.history.history['loss'], '-o')\n",
    "plt.plot(loc_model2.history.history['val_loss'], '-o')\n",
    "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box2 = loc_model2.predict(val_bbox_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(loc_val_mask[2][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_box2[2][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save  and load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc_model.save_weights('./models/locator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_model.load_weights('./models/locator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not amazing, but with this approach we can try fancier networks, like U-net.\n",
    "[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)\n",
    "\n",
    "We will need to change it a little bit because our input image is a lot smaller than the ones they used on their model, but the concept will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape=(64, 64, 3)):\n",
    "    \n",
    "    inputs = Input(((input_shape[0], input_shape[1], input_shape[2])))\n",
    "    \n",
    "    c_1 = Convolution2D(32, 3, activation='relu', padding='same', name='conv1_a')(inputs)\n",
    "    c_1 = Convolution2D(32, 3, activation='relu', padding='same', name='conv1_b')(c_1)\n",
    "    p_1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(c_1)\n",
    "\n",
    "    c_2 = Convolution2D(64, 3, activation='relu', padding='same', name='conv2_a')(p_1)\n",
    "    c_2 = Convolution2D(64, 3, activation='relu', padding='same', name='conv2_b')(c_2)\n",
    "    p_2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(c_2)\n",
    "\n",
    "    c_3 = Convolution2D(128, 3, activation='relu', padding='same', name='conv3_a')(p_2)\n",
    "    c_3 = Convolution2D(128, 3, activation='relu', padding='same', name='conv3_b')(c_3)\n",
    "    p_3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(c_3)\n",
    "\n",
    "    c_4 = Convolution2D(256, 3, activation='relu', padding='same', name='conv4_a')(p_3)\n",
    "    c_4 = Convolution2D(256, 3, activation='relu', padding='same', name='conv4_b')(c_4)\n",
    "    p_4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(c_4)\n",
    "\n",
    "    c_5 = Convolution2D(512, 3, activation='relu', padding='same', name='conv5_a')(p_4)\n",
    "    c_5 = Convolution2D(512, 3, activation='relu', padding='same', name='conv5_b')(c_5)\n",
    "\n",
    "    up_6 = concatenate([UpSampling2D(size=(2, 2))(c_5), c_4])\n",
    "    c_6 = Convolution2D(256, 3, activation='relu', padding='same', name='conv6_a')(up_6)\n",
    "    c_6 = Convolution2D(256, 3, activation='relu', padding='same', name='conv6_b')(c_6)\n",
    "\n",
    "    up_7 = concatenate([UpSampling2D(size=(2, 2))(c_6), c_3])\n",
    "    c_7 = Convolution2D(128, 3, activation='relu', padding='same', name='conv7_a')(up_7)\n",
    "    c_7 = Convolution2D(128, 3, activation='relu', padding='same', name='conv7_b')(c_7)\n",
    "\n",
    "    up_8 = concatenate([UpSampling2D(size=(2, 2))(c_7), c_2])\n",
    "    c_8 = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv8_a')(up_8)\n",
    "    c_8 = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv8_b')(c_8)\n",
    "\n",
    "    up_9 = concatenate([UpSampling2D(size=(2, 2))(c_8), c_1])\n",
    "    c_9 = Convolution2D(32, (3, 3), activation='relu', padding='same', name='conv9_a')(up_9)\n",
    "    c_9 = Convolution2D(32, (3, 3), activation='relu', padding='same', name='conv9_b')(c_9)\n",
    "\n",
    "    c_10 = Convolution2D(1, 1, activation='sigmoid')(c_9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[c_10])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = unet()\n",
    "unet_model.compile(Adam(lr=1e-4), loss=IOU_loss, metrics=[IOU_calc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.fit(trn_bbox_imgs, loc_trn_mask, batch_size=32, epochs=15,\n",
    "              validation_data=(val_bbox_imgs, loc_val_mask), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(unet_model.history.history['loss'], '-o')\n",
    "plt.plot(unet_model.history.history['val_loss'], '-o')\n",
    "plt.legend(['trn_loss', 'val_loss'], loc='upper right')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box_unet = unet_model.predict(val_bbox_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(loc_val_mask[2][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_box_unet[1][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_im_mask(val_bbox_imgs[500], pred_box_unet[500] * 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save  and load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unet_model.save_weights('./models/unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.load_weights('./models/unet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The last version of my localizer seems to be performing well on the realistic dataset. The accuracy of the predicted bounding boxes are a little under 90% as measured by the Dice coefficient. \n",
    "\n",
    "The SVHN test dataset already includes the coordinates for the bounding boxes on the test set and this was used to assess the performance of the model on step 2. Had this information had not been provided it's safe to assume that the model would have performed significantly worse, as suggested by our test cases on step 3. In that scenario, using the number locator we just trained should bring our performance back to the levels we saw in our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "Surprisingly the model was not able to generalize for the images that I used. I suspect that the poor results on the 64 x 64 pixels image is due to the loss of information you have when downsampling the original image.\n",
    "\n",
    "At 64  x 64 pixels it found the same \"blobs\" as probably the ones from where numbers were likely to be found, but the noise in the image ended up confusing the model.\n",
    "\n",
    "I also tried to use the same weights, but change the model input to 1024 x 1024 - given that this is a fully convolutional model, I assumed that the weights could be shared between models, but the results clearly show that they cannot.\n",
    "\n",
    "I suspect that given images that are more similar to the ones we have trained the model, it should perform better.\n",
    "\n",
    "I have provided the examples for both cases below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = []\n",
    "new_filenames = []\n",
    "\n",
    "filelist = os.listdir('./data/')\n",
    "\n",
    "for file in filelist:\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        img = None\n",
    "\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        new_images.append(img)\n",
    "        new_filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = np.array(new_images, dtype='float')\n",
    "proc_new_images = new_images / 255 - 0.5\n",
    "test_new_masks = unet_model.predict(proc_new_images, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 0 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 1 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 2 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 3 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 4 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = []\n",
    "new_filenames = []\n",
    "\n",
    "filelist = os.listdir('./data/')\n",
    "\n",
    "for file in filelist:\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread('./data/' + file, cv2.IMREAD_COLOR)\n",
    "    except:\n",
    "        img = None\n",
    "\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (1024, 1024))\n",
    "        new_images.append(img)\n",
    "        new_filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_large = unet(input_shape=(1024, 1024, 3))\n",
    "unet_large.load_weights('./models/unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = np.array(new_images, dtype='float')\n",
    "proc_new_images = new_images / 255 - 0.5\n",
    "test_new_masks = unet_large.predict(proc_new_images, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 0 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 1 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 2 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 3 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 4 \n",
    "plot_im_mask(new_images[ref], test_new_masks[ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
